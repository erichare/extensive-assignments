\section{Likelihood Analysis}

\subsection{Model Formulation}

Let $Y_{ij}$ be the proportional score of steak i in group j, i = 1,..,50 j = 1,2 \\
Let $X_{ij}$ be the storage time for steak i,j \\
Assume $Y_{ij}$ is independent over i and j. \\ \\

We assume $Y_{ij} \sim \text{Beta}(\alpha, \beta)$, and hence we can write the density as: \\

\begin{align*}
f(y | \alpha,\beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}y^{\alpha - 1}(1 - y)^{\beta - 1}, \quad 0 < y < 1, \quad \alpha > 0, \quad \beta > 0
\end{align*}

We can reparameterize this by noting the expected value and the variance of a Beta random variable. Letting $\mu_i = \frac{\alpha}{\alpha + \beta}$ and $\phi = \alpha + \beta$, we have: \\

\begin{align*}
f(y_i | \mu_i,\phi) = \frac{\Gamma(\phi)}{\Gamma(\mu_i\phi)\Gamma((1 - \mu_i)\phi)}y_i^{\mu_i\phi - 1}(1 - y_i)^{(1 - \mu_i)\phi - 1}, \quad 0 < y_i < 1, \quad 0 < \mu_i < 1, \quad \phi > 0
\end{align*}

\begin{align*}
E(Y)   &= \frac{\alpha}{\alpha + \beta} \\
       &= \mu \\ \\
Var(Y) &= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)} \\
       &= \frac{\mu_i(1 - \mu_i)}{\phi + 1}
\end{align*}

The likelihood is: \\

\begin{align*}
L &= \prod_{i=1}^n f(y_i | \mu_i,\phi) \\
  &= \prod_{i=1}^n \frac{\Gamma(\phi)}{\Gamma(\mu_i\phi)\Gamma((1 - \mu_i)\phi)}y_i^{\mu_i\phi - 1}(1 - y_i)^{(1 - \mu_i)\phi - 1}
\end{align*}

The log-likelihood is: \\

\begin{align*}
\ell(\mu_i, \phi) &= \sum_{i=1}^n \log f(y_i | \mu_i,\phi) \\
  &= \sum_{i=1}^n \log(\Gamma(\phi)) - \log(\Gamma(\mu_i\phi)) - \log(\Gamma((1 - \mu_i)\phi)) + (\mu_i\phi - 1)\log(y_i) + ((1 - \mu_i)\phi - 1)\log(1 - y_i)
\end{align*}

<<optim>>=
y <- meat.data$score1
x <- meat.data$time
phi <- 22.4064558

beta.fn <- function(par, y, x, phi) {
    mu <- exp(par[1] + par[2] * x) / (exp(par[1] + par[2] * x) + 1)
    
    return(sum(lgamma(phi) - lgamma(mu * phi) - lgamma(phi * (1 - mu)) + (mu * phi - 1) * log(y) + ((1 - mu) * phi - 1) * log(1 - y)))
}

optim(c(5, -0.5), fn=beta.fn, y = y, x = x, phi = phi, control=list(fnscale = -1), hessian=TRUE)
@

<<newtraph_beta>>=
beta.gradient <- function(par, y, x, phi) {
    T1 <- exp(par[1] + par[2] * x)
    mu <- 1 / (1 + exp(-(par[1] + par[2] * x)))
    
    dldmu <- -phi * digamma(mu * phi) + phi * digamma(phi - mu*phi) + phi * log(y) - phi * log(1 - y)
    dmudb0 <- T1 / (T1 + 1)^2
    dmudb1 <- x*T1 / (T1 + 1)^2
    
    dldb0 <- sum(dldmu * dmudb0)
    dldb1 <- sum(dldmu * dmudb1)
    
    return(c(dldb0, dldb1))
}

beta.hessian <- function(par, y, x, phi) {
    T1 <- exp(par[1] + par[2] * x)
    mu <- 1 / (1 + exp(-(par[1] + par[2] * x)))
    
    dldmu <- -phi * digamma(mu * phi) + phi * digamma(phi - mu*phi) + phi * log(y) - phi * log(1 - y)
    dmudb0 <- T1 / (T1 + 1)^2
    dmudb1 <- x*T1 / (T1 + 1)^2
    
    dldb0 <- sum(dldmu * dmudb0)
    dldb1 <- sum(dldmu * dmudb1)
    
    d2ldmu2 <- -phi^2 * trigamma(mu * phi) - phi^2 * trigamma(phi - mu * phi)
    d2mudb02 <- -T1 * (T1 - 1) / (T1 + 1)^3
    d2mudb12 <- -x^2 * T1 * (T1 - 1) / (T1 + 1)^3
    d2mudb0db1 <- -x * T1 * (T1 - 1) / (T1 + 1)^3
    
    d2ldb02 <- sum(d2ldmu2 * dmudb0 * dmudb0 + d2mudb02 * dldmu)
    d2ldb0db1 <- d2ldb1db0 <- sum(d2ldmu2 * dmudb0 * dmudb1 + d2mudb0db1 * dldmu)
    d2ldb12 <- sum(d2ldmu2 * dmudb1 * dmudb1 + d2mudb12 * dldmu)
    
    return(matrix(c(d2ldb02, d2ldb0db1, d2ldb1db0, d2ldb12), nrow = 2, byrow=TRUE))
}
@


\subsection{Derivatives}
  \subsubsection{First Derivatives}
  \begin{align*}
  \frac{\partial \ell_i}{\partial \beta_j} &=  \frac{\partial \ell_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \beta_j}   \quad \text{for $j=0,1$}
  \end{align*}
  \begin{align*}
   \frac{\partial \ell_i}{\partial \mu_i} &= -\phi\Gamma'(\mu_i\phi) + \phi\Gamma'(\phi - \mu_i\phi) + \phi\log{(y_i)} - \phi\log{(1 - y_i)} \\
   \frac{\partial \mu_i}{\partial \beta_0} &= \frac{e^{\beta_0 + \beta_1x_i}}{(e^{\beta_0 + \beta_1x_i} + 1)^2} \\
   \frac{\partial \mu_i}{\partial \beta_1} &= \frac{x_ie^{\beta_0 + \beta_1x_i}}{(e^{\beta_0 + \beta_1x_i} + 1)^2} \\
  \end{align*}
  
  \subsubsection{Second Derivatives}
    \begin{align*}
    \frac{\partial^2 \ell_i}{\partial \beta_j^2} &= \frac{\partial^2 \ell_i}{\partial \mu_i^2}\frac{\partial \mu_i}{\partial \beta_j} +\frac{\partial^2 \mu_i}{\partial \beta_j^2}\frac{\partial \ell_i}{\partial \mu_i}  \quad \text{for $j=0,1$} \\
    \frac{\partial^2 \ell_i}{\partial \beta_0\beta_1} &= \frac{\partial^2 \ell_i}{\partial \mu_i^2} \frac{\partial \mu_i}{\partial \beta_0} \frac{\partial \mu_i}{\partial \beta_1}+ \frac{\partial^2 \mu_i}{\partial \beta_0 \partial \beta_1}\frac{\partial \ell_i}{\partial \mu_i} =  \frac{\partial^2 \ell_i}{\partial \beta_1\beta_0} \\
    \frac{\partial^2 \ell_i}{\partial \mu_i^2} &= -\phi^2\Gamma''(\mu_i\phi) - \phi^2\Gamma''(\phi - \mu_i\phi) \\
    \frac{\partial^2 \mu_i}{\partial \beta_0^2} &= -\frac{e^{(\beta_0 + \beta_1x_i)}(e^{(\beta_0 + \beta_1x_i)} - 1)}{(e^{(\beta_0 + \beta_1x_i)})^3} \\
    \frac{\partial^2 \mu_i}{\partial \beta_1^2} &= -x_i^2\frac{e^{(\beta_0 + \beta_1x_i)}(e^{(\beta_0 + \beta_1x_i)} - 1)}{(e^{(\beta_0 + \beta_1x_i)})^3} \\
    \frac{\partial^2 \mu_i}{\partial \beta_0\beta_1^2} &= -x_i\frac{e^{(\beta_0 + \beta_1x_i)}(e^{-(\beta_0 + \beta_1x_i)} - 1)}{(e^{(\beta_0 + \beta_1x_i)})^3} \\
    \end{align*}
    
    <<newtraph, echo=TRUE>>=
newton.raphson <- function(loglik, gradient, hessian, start, lower = rep(-Inf, length(start)), upper = rep(Inf, length(start)), tol = rep(1e-2, 3), max.iterations = 100, step.halving = TRUE, debug = FALSE, ...) {
    current <- start
    conditions <- TRUE
    
    iterations <- 0
    while (TRUE) {        
        new <- as.vector(current - solve(hessian(current, ...)) %*% gradient(current, ...))
        new[new < lower] <- lower[new < lower] + tol[1]
        new[new > upper] <- upper[new > upper] - tol[1]
        
        if(!(any(abs(gradient(new, ...)) > tol[1]) | loglik(new, ...) - loglik(current, ...) > tol[2] | dist(rbind(current, new))[1] > tol[3])) break;
        
        if (debug) cat(paste("Current loglik is", loglik(current, ...), "\n"))
        if (debug) cat(paste("New is now", new, "\n"))
        if (debug) cat(paste("New loglik is", loglik(new, ...), "\n"))
        
        if (step.halving & (loglik(new, ...) < loglik(current, ...))) {
            if (debug) cat("Uh oh, time to fix this\n")
            m <- 1
            while (m < max.iterations & loglik(new, ...) < loglik(current, ...)) {
                new <- as.vector(current - (1 / (2 * m)) * solve(hessian(current, ...)) %*% gradient(current, ...))
                m <- 2*m;
            }
            if (debug) cat(paste("We have fixed it! its now", new, "\n"))
            if (debug) cat(paste("And the new loglik is finally", loglik(new, ...), "\n"))
        }
        
        iterations <- iterations + 1
        if (iterations > max.iterations) {
            if (debug) cat(paste("Didn't converge in", max.iterations, "iterations\n"))
            break;
        }
                
        if (debug) cat("\n")
        
        current <- new
    }
    
    return(list(loglik = loglik(new, ...), par = new))
}
@

<<profile_code>>=

y <- meat.data$score1
phis <- seq(21, 23, by = 0.01)
profile.beta1 <- ldply(phis, function(phi) {
    c(phi = phi, unlist(newton.raphson(beta.fn, beta.gradient, beta.hessian, start = c(2, -0.2), y = y, x = x, phi = phi)))
})
profile.beta1[which.max(profile.beta1$loglik), ]

y <- meat.data$score2
phis <- seq(6, 8, by = 0.01)
profile.beta2 <- ldply(phis, function(phi) {
    c(phi = phi, unlist(newton.raphson(beta.fn, beta.gradient, beta.hessian, start = c(2, -0.2), y = y, x = x, phi = phi)))
})
profile.beta2[which.max(profile.beta2$loglik), ]

y <- c(meat.data$score1, meat.data$score2)
x <- c(meat.data$time, meat.data$time)
phis <- seq(6, 8, by = 0.01)
profile.betacomb <- ldply(phis, function(phi) {
    c(phi = phi, unlist(newton.raphson(beta.fn, beta.gradient, beta.hessian, start = c(2, -0.2), y = y, x = x, phi = phi)))
})
profile.betacomb[which.max(profile.betacomb$loglik), ]
@


\subsection{Comparison to betareg Package}

<<betareg, echo=FALSE>>=
betareg(score1 ~ time, data = meat.data)
betareg(score2 ~ time, data = meat.data)

meat.data.comb <- data.frame(score = c(meat.data$score1, meat.data$score2), time = rep(meat.data$time, 2))
betareg(score ~ time, data = meat.data.comb)
@

